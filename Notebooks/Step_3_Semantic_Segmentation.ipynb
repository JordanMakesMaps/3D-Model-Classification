{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('keras')\n",
    "\n",
    "import keras\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapOnImage\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Valid\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Branching', 'Fish', 'Massive', 'Not Massive', 'Substrate', 'Target', 'Water']\n",
    "\n",
    "labels = {'Branching' : 0, \n",
    "          'Fish' : 1, \n",
    "          'Massive' : 2,\n",
    "          'Not Massive' : 3,\n",
    "          'Substrate' : 4,\n",
    "          'Target' : 5,\n",
    "          'Water' : 6}\n",
    "\n",
    "NO_LABEL = 255\n",
    "\n",
    "\n",
    "cp = np.array([ [178,24,43],\n",
    "                [239,138,98],\n",
    "                [253,219,199],\n",
    "                [247,247,247],\n",
    "                [209,229,240],\n",
    "                [103,169,207],\n",
    "                [33,102,172] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Z:\\\\Photogrammetry_data\\\\Florida\\\\7_16_2019_patch\\\\models\\\\before-algae\\\\Deep Learning\\\\data\\\\\"\n",
    "\n",
    "images = sorted(glob.glob(path + \"images\\\\*.png\"))\n",
    "masks = sorted(glob.glob(path + \"dense\\\\*.png\"))\n",
    "points = sorted(glob.glob(path + \"sparse\\\\*.csv\"))\n",
    "\n",
    "data = pd.DataFrame(list(zip(images, masks, points)), columns = ['Images', 'Masks', 'Points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size = .1)\n",
    "\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "valid.reset_index(drop = True, inplace = True)\n",
    "\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original 2160, 3840\n",
    "# Must be divisible by 32(?)\n",
    "height, width = 736, 1280 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_prediction(pred):\n",
    "   \n",
    "    colored_mask = np.zeros(shape = (pred.shape[0], pred.shape[1], 3))\n",
    "\n",
    "    for _ in np.unique(pred):\n",
    "           \n",
    "            colored_mask[pred == _] = cp[_]/255.0\n",
    "        \n",
    "    return colored_mask\n",
    "\n",
    "# Augmentation methods\n",
    "augs_for_images = iaa.Sequential([iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'linear',\n",
    "                                            random_state = 5),\n",
    "                                  iaa.Fliplr(0.25, random_state = 1),\n",
    "                                  iaa.Flipud(0.25, random_state = 2),\n",
    "                                  iaa.Rot90([1, 2, 3, 4], True, random_state = 3)\n",
    "                       ])\n",
    "\n",
    "\n",
    "augs_for_masks = iaa.Sequential([iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'nearest',\n",
    "                                           random_state = 5),\n",
    "                                  iaa.Fliplr(0.25, random_state = 1),\n",
    "                                  iaa.Flipud(0.25, random_state = 2),\n",
    "                                  iaa.Rot90([1, 2, 3, 4], True, random_state = 3)\n",
    "                                ])\n",
    "\n",
    "\n",
    "\n",
    "resize_for_images = iaa.Sequential([\n",
    "     iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'linear', random_state = 1),\n",
    "])\n",
    "\n",
    "resize_for_masks = iaa.Sequential([\n",
    "     iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'nearest', random_state = 1),\n",
    "])\n",
    "\n",
    "\n",
    "# Image data generator class\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, dataframe, batch_size, augment, n_classes = 8):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.augment = augment\n",
    "          \n",
    "        \n",
    "    # Steps per epoch    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) // self.batch_size\n",
    "    \n",
    "    # Shuffles and resets the index at the end of training epoch\n",
    "    def on_epoch_end(self):\n",
    "        self.dataframe = self.dataframe.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    # Generates data, feeds to training\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        global preprocess_input\n",
    "        \n",
    "        processed_images = []\n",
    "        processed_masks = []\n",
    "        \n",
    "        for _ in range(self.batch_size):\n",
    "\n",
    "            the_image = io.imread(self.dataframe['Images'][index])\n",
    "            the_mask = io.imread(self.dataframe['Masks'][index]).astype('uint8');\n",
    "            one_hot_mask = to_categorical(the_mask, 7)\n",
    "            \n",
    "            if(self.augment):\n",
    "                \n",
    "                processed_image = augs_for_images(image = the_image)\n",
    "                processed_mask = augs_for_masks(image = one_hot_mask)\n",
    "         \n",
    "            else:\n",
    "                # Still resizing and then random cropping, but no augmentations   \n",
    "                processed_image = resize_for_images(image = the_image)\n",
    "                processed_mask = resize_for_masks(image = one_hot_mask)\n",
    "\n",
    "            processed_images.append(preprocess_input(processed_image))\n",
    "            processed_masks.append(processed_mask)\n",
    "\n",
    "                \n",
    "        batch_x = np.array( processed_images )\n",
    "        batch_y = np.array( processed_masks )\n",
    "        \n",
    "        return (batch_x, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for training      \n",
    "batch_size = 1\n",
    "num_epochs = 100\n",
    "\n",
    "train_steps = len(train) // batch_size; print(train_steps)\n",
    "valid_steps = len(valid) // batch_size; print(valid_steps)\n",
    "\n",
    "train_gen = DataGenerator(train, batch_size = batch_size, augment = True) \n",
    "valid_gen = DataGenerator(valid, batch_size = batch_size, augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View image and mask \n",
    "r = np.random.randint(len(data))\n",
    "\n",
    "print(data.Images[r].split(\"\\\\\")[-1])\n",
    "\n",
    "the_image = io.imread(data['Images'][r])\n",
    "the_mask = io.imread(data['Masks'][r])\n",
    "the_cpce = pd.read_csv(data['Points'][r])\n",
    "\n",
    "colors = [cp[labels[label]]/255.0 for label in the_cpce.Labels.values]\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(the_image)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Sparse Points\")\n",
    "plt.imshow(the_image)\n",
    "plt.scatter(the_cpce.X.values, the_cpce.Y.values, s = 30, c = colors)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Mask (SLIC)\")\n",
    "plt.imshow(colorize_prediction(the_mask), alpha = .85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb0'\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE) \n",
    "\n",
    "model = sm.Unet(input_shape = (None, None, 3), \n",
    "                backbone_name = BACKBONE, \n",
    "                encoder_weights = 'noisy-student', # 'imagenet'\n",
    "                activation = 'softmax', \n",
    "                classes = 7,\n",
    "                encoder_freeze = True,\n",
    "                decoder_use_batchnorm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from segmentation_models.metrics import precision, recall, iou_score\n",
    "from segmentation_models.losses import cce_jaccard_loss\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "metrics = ['accuracy', iou_score, precision, recall]\n",
    "\n",
    "model.compile(optimizer = Adam(lr = .001), \n",
    "              loss = [cce_jaccard_loss], \n",
    "              metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "holla = [\n",
    "         ReduceLROnPlateau(monitor = 'val_loss', factor = .65, patience = 2, verbose = 1),\n",
    "         \n",
    "         ModelCheckpoint(filepath = 'weights\\\\SS\\\\Florida_' + BACKBONE + '_.h5', \n",
    "                         monitor = 'val_loss', save_weights_only = True, \n",
    "                         save_best_only = True, verbose = 1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator = train_gen, \n",
    "                              steps_per_epoch = train_steps, \n",
    "                              epochs = num_epochs, \n",
    "                              validation_data = valid_gen,\n",
    "                              validation_steps = valid_steps,\n",
    "                              verbose = 1,\n",
    "                              callbacks = holla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.argmin(history.history[\"val_loss\"]), \n",
    "         np.min(history.history[\"val_loss\"]), \n",
    "         marker = \"x\", color = \"b\", label = \"best model\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot(history.history[\"precision\"], label=\"precision\")\n",
    "plt.plot(history.history[\"val_precision\"], label=\"val_precision\")\n",
    "plt.title(\"Training Precision\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot(history.history[\"recall\"], label=\"recall\")\n",
    "plt.plot(history.history[\"val_recall\"], label=\"val_recall\")\n",
    "plt.title(\"Training Recall\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights\\\\SS\\\\Florida_\" + BACKBONE + '_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the size of the test image provides slightly different results\n",
    "# find the dimension(s) that provide the best testing-time augmentation for you\n",
    "# This only works if the model was initialized with input shape (None, None, 3)\n",
    "\n",
    "# 736,  1280 - .35\n",
    "# 1088, 1920 - .5\n",
    "# 1408, 2496 - .65\n",
    "# 1632, 2880 - .75\n",
    "# 1824, 3200 - .85\n",
    "# 1984, 3680 - .92\n",
    "# 2144, 3840 - .99\n",
    "\n",
    "\n",
    "h = [1088, 1408, 1632, 1824]\n",
    "w = [1920, 2496, 2880, 3200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(dataframe):\n",
    "    \n",
    "    index = np.random.randint(len(dataframe))\n",
    "\n",
    "    image = io.imread(dataframe['Images'][index])\n",
    "    mask = io.imread(dataframe['Masks'][index])\n",
    "    \n",
    "    return image, mask, index\n",
    "\n",
    "\n",
    "def mode(a, axis = 0):\n",
    "\n",
    "    a = np.array(a)\n",
    "    scores = np.unique(np.ravel(a))  # all unique values\n",
    "    testshape = list(a.shape)        # dimensions of array\n",
    "    testshape[axis] = 1\n",
    "    oldmostfreq = np.zeros(testshape, dtype = int)    \n",
    "    oldcounts = np.zeros(testshape, dtype = int)       \n",
    "\n",
    "    for score in scores:\n",
    "\n",
    "        template = (a == score)                                 \n",
    "        counts = np.expand_dims(np.sum(template, axis), axis)\n",
    "\n",
    "        mostfrequent = np.where(counts > oldcounts, score, oldmostfreq)  \n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldmostfreq = mostfrequent\n",
    "\n",
    "    return mostfrequent[0]\n",
    "\n",
    "\n",
    "def make_prediction(image):\n",
    "    \n",
    "    masks = []\n",
    "    predictions = []\n",
    "    \n",
    "    if(True):\n",
    "        \n",
    "        for _ in range(3):\n",
    "    \n",
    "            resized_image = iaa.Resize({'height' : h[_], 'width' : w[_]}).augment_image(image = image)\n",
    "\n",
    "            y_pred = model.predict(np.expand_dims(preprocess_input(resized_image), axis = 0)).squeeze()\n",
    "            \n",
    "            y_pred = iaa.Resize({'height' : image.shape[0], \n",
    "                                 'width' : image.shape[1]}, \n",
    "                                      interpolation = 'nearest').augment_image(image = y_pred)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            \n",
    "            mask = np.argmax(y_pred, axis = 2).astype(\"uint8\"); \n",
    "            \n",
    "            masks.append(mask)\n",
    "\n",
    "    return mode(np.array(masks)), predictions\n",
    "\n",
    "\n",
    "def compare_results(image, mask, y_pred):\n",
    "\n",
    "    plt.figure(figsize = (20, 15))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Prediction\")  \n",
    "    plt.imshow(colorize_prediction(y_pred))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Overlaid\")\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(colorize_prediction(y_pred), alpha = .65)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting the predictions and comparing them\n",
    "for _ in range(1):\n",
    "    \n",
    "    image, mask, index = get_random_sample(data)\n",
    "    y_pred, predictions = make_prediction(image)\n",
    "\n",
    "    compare_results(image, mask, y_pred)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold to view only the predictions that model is confident about\n",
    "# black out the regions it isn't.\n",
    "threshold = .65\n",
    "\n",
    "filtered_masks = []\n",
    "\n",
    "for prediction in predictions:\n",
    "\n",
    "    first = np.sort(prediction)[:, :, -1]\n",
    "    second = np.sort(prediction)[:, :, -2]\n",
    "\n",
    "    diff = first - second\n",
    "    confidence = diff < threshold\n",
    "\n",
    "    filtered_mask = np.argmax(prediction, axis = 2)\n",
    "    filtered_mask[confidence] = 7\n",
    "    \n",
    "    filtered_masks.append(filtered_mask)\n",
    "    \n",
    "filtered_masks = mode(np.array(filtered_masks))\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "plt.imshow(image)\n",
    "plt.imshow(colorize_prediction(filtered_mask), alpha = .75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
